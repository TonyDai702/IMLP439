# IMLP439

## WEEK1  [HW1](https://github.com/TonyDai702/IMLP439/tree/main/Unit01)  
Introduction to for/while loop, some useful modules such as os, shutil; and how to manipulate the file.  
Further info regarding encoding, decoding needed.  

## WEEK2  [HW2](https://github.com/TonyDai702/IMLP439/tree/main/Unit02)  
**[Introduction to NumPy]**  
  
**[Introduction to Pandas]**  
    
**[Introduction to MatplotLib]**  
      
**[Introduction to SeaBorn]**(Seems to be preferred over Matplotlib)       
1. sns.set(context='', style='', palette='', font='', font_scale='', color_codes='', rc='')  
2. distplot, jointplot, regression, violin plot, box plot  

## WEEK3  [HW3](https://github.com/TonyDai702/IMLP439/tree/main/Unit03)  
**[Introduction to AI, ML, and cross validation]**    
**[Introduction to features, scaling, similarity]**   
1. normalization, standardization scaling  
2. Euclidean, cosine distance  
  
**[Scikit-learn, feature encoding]**   
1. one hot encoding: Sklearn, pd.getdummies  
2. Label encoding: LabelEncoder, or directly using .map() function  
   
## WEEK4  [HW4](https://github.com/TonyDai702/IMLP439/blob/main/Unit04/Linear%20Regression_HW.ipynb)  
**[Linear Regression]**  
1. Loss function, calculation of MAE, MSE, RMSD  
2. regr.coef_[0] (Please don't forget to add [0] if you only want to get the first one)  
3. Lasso and Ridge Regularization  
4. Gradient Descent practice  
  
## WEEK5  [HW5](https://github.com/TonyDai702/IMLP439/tree/main/Unit05)  
**[Supervised Learning - classification: Logistic regression & KNN]**  
**[Supervised Learning - classification: SVM, Decision Tree, Random Forest]**  
1. For SVM, refer to the [link](https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E6%94%AF%E6%92%90%E5%90%91%E9%87%8F%E6%A9%9F-support-vector-machine-svm-%E8%A9%B3%E7%B4%B0%E6%8E%A8%E5%B0%8E-c320098a3d2e)  
2. For Random Forest Automatic tuning of hyperparameter, can see tqdm **(Get back to here after offer is made)**  
  
## WEEK6  [HW6]()  
**[Ensemble learning]**  
1. Introduction to confusion matrix, ROC, AUC  
2. bagging (parallel), boosting (sequential)  